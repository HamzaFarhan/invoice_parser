{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from invoice_parser.imports import *\n",
    "from invoice_parser.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is Invoice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def page0_text(pdf):\n",
    "    loaded_pdf = PdfReader(pdf)\n",
    "    p = loaded_pdf.pages[0]\n",
    "    return p.extract_text()\n",
    "\n",
    "\n",
    "def is_invoice_text(text, model):\n",
    "    return model(text).detach().cpu().item() == 0\n",
    "\n",
    "\n",
    "def is_invoice(pdf, model, device=None):\n",
    "    if model is None:\n",
    "        model = load_invoice_model(device=device)\n",
    "    return is_invoice_text(page0_text(pdf), model)\n",
    "\n",
    "\n",
    "def is_invoice_chain(\n",
    "    model,\n",
    "    device=None,\n",
    "    input_variables=[\"pdf\"],\n",
    "    output_variables=[\"is_invoice\"],\n",
    "    verbose=False,\n",
    "):\n",
    "    return transform_chain(\n",
    "        is_invoice,\n",
    "        transform_kwargs={\"model\": model, \"device\": device},\n",
    "        vars_kwargs_mapping={input_variables[0]: \"pdf\"},\n",
    "        input_variables=input_variables,\n",
    "        output_variables=output_variables,\n",
    "        verbose=verbose,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "vline_settings = {\n",
    "    \"horizontal_strategy\": \"text\",\n",
    "    \"vertical_strategy\": \"lines\",\n",
    "    \"intersection_x_tolerance\": 5,\n",
    "    \"snap_y_tolerance\": 5,\n",
    "    \"join_x_tolerance\": 5,\n",
    "    \"join_y_tolerance\": 5,\n",
    "}\n",
    "hline_settings = {\n",
    "    \"horizontal_strategy\": \"lines\",\n",
    "    \"vertical_strategy\": \"text\",\n",
    "    \"intersection_x_tolerance\": 5,\n",
    "    \"snap_y_tolerance\": 5,\n",
    "    \"join_x_tolerance\": 5,\n",
    "    \"join_y_tolerance\": 5,\n",
    "}\n",
    "line_settings = {\n",
    "    \"horizontal_strategy\": \"lines\",\n",
    "    \"vertical_strategy\": \"lines\",\n",
    "    \"intersection_x_tolerance\": 5,\n",
    "    \"snap_y_tolerance\": 5,\n",
    "    \"join_x_tolerance\": 5,\n",
    "    \"join_y_tolerance\": 5,\n",
    "}\n",
    "text_settings = {\n",
    "    \"horizontal_strategy\": \"text\",\n",
    "    \"vertical_strategy\": \"text\",\n",
    "    \"intersection_x_tolerance\": 5,\n",
    "    \"snap_y_tolerance\": 5,\n",
    "    \"join_x_tolerance\": 5,\n",
    "    \"join_y_tolerance\": 5,\n",
    "}\n",
    "text_settings = {\n",
    "    # \"intersection_x_tolerance\": 5,\n",
    "    # \"snap_y_tolerance\": 5,\n",
    "    # \"join_x_tolerance\": 5,\n",
    "    # \"join_y_tolerance\": 5,\n",
    "    \"text_layout\": True\n",
    "}\n",
    "\n",
    "\n",
    "def get_fullest_row(table):\n",
    "    rows = [r for r in table if full_row(r)]\n",
    "    if len(rows) == 0:\n",
    "        rows = table\n",
    "    row = max(rows, key=len)\n",
    "    return row, table.index(row)\n",
    "\n",
    "\n",
    "def num_full_parts(row):\n",
    "    return len([p for p in row if not empty_part(p)])\n",
    "\n",
    "\n",
    "def get_table_items(table):\n",
    "    if table is None or len(table) == 0:\n",
    "        return []\n",
    "\n",
    "    cols, cols_idx = get_fullest_row(table)\n",
    "    for i, c in enumerate(cols):\n",
    "        if empty_part(c):\n",
    "            cols[i] = f\"col_{i}\"\n",
    "\n",
    "    # let's assume that the first full row after the cols row is the first item\n",
    "    first_order_row_idx = get_first_full_row(table[cols_idx + 1 :])[1]\n",
    "    if first_order_row_idx is None:\n",
    "        first_order_row_idx = get_first_non_empty_row(table[cols_idx + 1 :])[1]\n",
    "    if first_order_row_idx is None:\n",
    "        first_order_row_idx = 0\n",
    "    first_order_row_idx += cols_idx + 1\n",
    "\n",
    "    items = []\n",
    "    item = {c: \"\" for c in cols}\n",
    "    first_order_row_idx = min(first_order_row_idx, len(table) - 1)\n",
    "    order_table = table[first_order_row_idx:]\n",
    "    curr_row_len = num_full_parts(order_table[0])\n",
    "    for row in order_table:\n",
    "        if ((num_full_parts(row) == curr_row_len) or empty_row(row)) and len(item) > 0:\n",
    "            items.append(item)\n",
    "            item = {c: \"\" for c in cols}\n",
    "            if not empty_row(row):\n",
    "                curr_row_len = num_full_parts(row)\n",
    "        for i, c in enumerate(cols):\n",
    "            row_part = row[i]\n",
    "            if not empty_part(row_part):\n",
    "                row_part = \" \".join(row[i].split(\"\\n\"))\n",
    "                item[c] += row_part + \" \"\n",
    "    items.append(item)\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def row_check(row, target_list, target_thresh=2):\n",
    "    \"\"\"\n",
    "    Checks if the given row contains the target elements.\n",
    "\n",
    "    Parameters:\n",
    "        row (str): A string representing the row to check.\n",
    "        target_list (list): A list of strings representing the target elements.\n",
    "        target_thresh (int): The minimum number of target elements that must be present in the row.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the row contains the target elements, False otherwise.\n",
    "    \"\"\"\n",
    "    check_list = [hc for hc in target_list if hc.lower() in row.strip().lower()]\n",
    "    return len(check_list) >= target_thresh\n",
    "\n",
    "\n",
    "def extract_sub_text(\n",
    "    text,\n",
    "    top_cols,\n",
    "    bottom_cols,\n",
    "    top_thresh=2,\n",
    "    bottom_thresh=1,\n",
    "    alt_top_index=0,\n",
    "    alt_bottom_index=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts the text between the top_cols and bottom_cols.\n",
    "    \"\"\"\n",
    "    top_idx = find_target_index(\n",
    "        text, top_cols, target_thresh=top_thresh, alt_index=alt_top_index\n",
    "    )\n",
    "    bottom_idx = find_target_index(\n",
    "        text[::-1], bottom_cols, target_thresh=bottom_thresh, alt_index=alt_bottom_index\n",
    "    )\n",
    "    bottom_idx = len(text) - bottom_idx\n",
    "    return (\n",
    "        [t for t in text[top_idx : bottom_idx + 1] if len(t.strip()) > 0],\n",
    "        top_idx,\n",
    "        bottom_idx,\n",
    "    )\n",
    "\n",
    "\n",
    "def find_target_index(data, target_list, target_thresh=2, alt_index=0):\n",
    "    \"\"\"\n",
    "    Finds the index of the row in the given data that contains the target elements.\n",
    "\n",
    "    Parameters:\n",
    "        data (list): A list of strings representing the data.\n",
    "        target_list (list): A list of strings representing the target elements.\n",
    "        target_thresh (int): The minimum number of target elements that must be present in a row.\n",
    "\n",
    "    Returns:\n",
    "        int: The index of the row that contains the target elements. If no such row exists, returns alt_index.\n",
    "    \"\"\"\n",
    "    target_idx = None\n",
    "    for idx, row in enumerate(data):\n",
    "        if row_check(row, target_list, target_thresh):\n",
    "            target_idx = idx\n",
    "            break\n",
    "    if target_idx is None:\n",
    "        msg.warn(f\"No target found in data. Setting it to {alt_index}.\", spaced=True)\n",
    "        target_idx = alt_index\n",
    "    return target_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def json_str(x):\n",
    "    x = x[x.find(\"{\") : x.rfind(\"}\") + 1]\n",
    "    x = x.splitlines()\n",
    "    jstr = [x[0]]\n",
    "    for s in x[1:]:\n",
    "        if \":\" not in s and s.strip() != \"}\":\n",
    "            jstr[-1] = jstr[-1][:-2] + \" \" + s[1:]\n",
    "        else:\n",
    "            jstr.append(s)\n",
    "    jstr = \" \".join(jstr).strip()\n",
    "    if jstr[-1] in [\",\", \";\"]:\n",
    "        jstr = jstr[:-1].strip()\n",
    "    jstr = jstr.replace(\",}\", \"}\")\n",
    "    jstr = re.sub(r\"\\s+\", \" \", jstr)\n",
    "    jstr = jstr.replace('\" ', '\"')\n",
    "    jstr = jstr.replace(' \"', '\"')\n",
    "    jstr = jstr.replace(\", }\", \"}\")\n",
    "    jstr = re.sub(r\"[a-zA-Z0-9]\\}\", '\"}', jstr)\n",
    "    jstr = re.sub(r\":\\s*(\\w)\", r': \"\\1', jstr)\n",
    "    jstr = re.sub(r\"\\b0+(\\d+)\\b\", r\"\\1\", jstr)\n",
    "    # jstr = re.sub(r\"\\s*([{}])\\s*\", r\"\\1\", jstr)\n",
    "    jstr = re.sub(r\"\\s*([:,])\\s*\", r\"\\1 \", jstr)\n",
    "    jstr = re.sub(r\",}\", '\"}', jstr)\n",
    "    jstr = re.sub(r\"\\\"+}\", '\"}', jstr)\n",
    "    jstr = jstr.replace('\"\"', '\",\"')\n",
    "    return jstr\n",
    "\n",
    "\n",
    "def str_to_json(x, max_try=10):\n",
    "    # jstr = json_str(x)\n",
    "    jstr = x[x.find(\"{\") : x.rfind(\"}\") + 1]\n",
    "    jstr = jstr.replace(': \",', ': \"\",')\n",
    "    json_dict = {}\n",
    "    tries = 0\n",
    "    while True and tries < max_try:\n",
    "        try:\n",
    "            json_dict = json.loads(jstr)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            unexp = int(re.findall(r\"\\(char (\\d+)\\)\", str(e))[0])\n",
    "            unesc = jstr.rfind(r'\"', 0, unexp)\n",
    "            jstr = jstr[:unesc] + r\"\\\"\" + jstr[unesc + 1 :]\n",
    "            closg = jstr.find(r'\"', unesc + 2)\n",
    "            jstr = jstr[:closg] + r\"\\\"\" + jstr[closg + 1 :]\n",
    "            tries += 1\n",
    "    return jstr, json_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def extract_text(path):\n",
    "    data = pdfplumber.open(path)\n",
    "    pdf_text = [p.extract_text(layout=True).splitlines() for p in data.pages]\n",
    "    text = pdf_text[0]\n",
    "    return text\n",
    "\n",
    "\n",
    "def extract_order_docs(\n",
    "    text,\n",
    "    header_cols=[\"item\", \"description\", \"price\", \"quantity\", \"amount\", \"total\", \"qty\"],\n",
    "    get_parts=False,\n",
    "    splitter=None,\n",
    "    chunk_size=4000,\n",
    "    chunk_overlap=0,\n",
    "):\n",
    "    if splitter is None:\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            separators=[\"\\n\\n\"], chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "        )\n",
    "    avg_len = mode([len(t) for t in text])\n",
    "    order_text = [text[0]]\n",
    "    order_metadatas = [{}]\n",
    "    desc = \"\"\n",
    "    # for i, txt in enumerate(text[1:-1], start=1):\n",
    "    for txt in text[1:-1]:\n",
    "        if not len(txt) >= avg_len * 2:\n",
    "            txt = txt.replace('\"', \"\").replace(\"'\", \"\").strip()\n",
    "            if row_check(txt, header_cols, 2):\n",
    "                order_text.append(txt)\n",
    "                order_metadatas.append({})\n",
    "            elif len(txt) < avg_len * 0.75 and not row_check(\n",
    "                order_text[-1], header_cols, 2\n",
    "            ):\n",
    "                desc += \" \" + txt\n",
    "            else:\n",
    "                if len(desc) > 0:\n",
    "                    order_metadatas.append({\"desc\": desc.strip()})\n",
    "                    desc = \"\"\n",
    "                if get_parts:\n",
    "                    part_nums = [\n",
    "                        x\n",
    "                        for x in re.findall(r\"\\d{5}\", txt)\n",
    "                        if not x.startswith(\"00\") and \".\" not in x\n",
    "                    ]\n",
    "                    if len(part_nums) == 0:\n",
    "                        part_nums = [\n",
    "                            x\n",
    "                            for x in re.findall(r\"\\d{4}\", txt)\n",
    "                            if not x.startswith(\"00\") and \".\" not in x\n",
    "                        ]\n",
    "                    if len(part_nums) > 0:\n",
    "                        part_num = part_nums[0]\n",
    "                        txt += f\" part_number: {part_num}\"\n",
    "                order_text.append(txt)\n",
    "    if len(desc) > 0:\n",
    "        order_metadatas.append({\"desc\": desc.strip()})\n",
    "    order_text.append(text[-1])\n",
    "    order_metadatas += [{} for _ in range(len(order_text) - len(order_metadatas))]\n",
    "    return splitter.create_documents(order_text, metadatas=order_metadatas)\n",
    "\n",
    "\n",
    "def info_order_docs(\n",
    "    text,\n",
    "    header_cols=[\"item\", \"description\", \"price\", \"quantity\", \"amount\", \"total\", \"qty\"],\n",
    "    total_cols=[\"total\", \"subtotal\", \"tax\"],\n",
    "    chunk_size=4000,\n",
    "    chunk_overlap=0,\n",
    "    get_parts=False,\n",
    "):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\"], chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    table_text, top_idx, bottom_idx = extract_sub_text(\n",
    "        text,\n",
    "        top_cols=header_cols,\n",
    "        bottom_cols=total_cols,\n",
    "        top_thresh=2,\n",
    "        bottom_thresh=1,\n",
    "        alt_top_index=0,\n",
    "        alt_bottom_index=0,\n",
    "    )\n",
    "\n",
    "    top_text = [\n",
    "        t.replace('\"', \"\").replace(\"'\", \"\").strip()\n",
    "        for t in text[:top_idx]\n",
    "        if len(t.strip()) > 0\n",
    "    ]\n",
    "    bottom_text = [\n",
    "        t.replace('\"', \"\").replace(\"'\", \"\").strip()\n",
    "        for t in text[bottom_idx:]\n",
    "        if len(t.strip()) > 0\n",
    "    ]\n",
    "    info_text = top_text + bottom_text\n",
    "    info_docs = splitter.create_documents(info_text)\n",
    "    order_docs = extract_order_docs(\n",
    "        table_text, header_cols=header_cols, get_parts=get_parts, splitter=splitter\n",
    "    )\n",
    "    return dict(info_docs=info_docs, order_docs=order_docs)\n",
    "\n",
    "\n",
    "def pdf_to_info_order_docs(\n",
    "    path,\n",
    "    header_cols=[\"item\", \"description\", \"price\", \"quantity\", \"amount\", \"total\", \"qty\"],\n",
    "    total_cols=[\"total\", \"subtotal\", \"tax\"],\n",
    "    chunk_size=4000,\n",
    "    chunk_overlap=0,\n",
    "    get_parts=False,\n",
    "):\n",
    "    text = extract_text(path)\n",
    "    return info_order_docs(\n",
    "        text,\n",
    "        header_cols=header_cols,\n",
    "        total_cols=total_cols,\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        get_parts=get_parts,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = default_device()\n",
    "\n",
    "# embeddings = SentenceTransformerEmbeddings(\n",
    "#     model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "#     model_kwargs={\"device\": default_device()},\n",
    "# )\n",
    "# model = \"tiiuae/falcon-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def qa_llm_chain(model=\"meta-llama/Llama-2-7b-chat-hf\"):\n",
    "    token = \"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\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model, token=token)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model,device_map='auto', torch_dtype=torch.float16, token=token)\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=True,\n",
    "        top_k=5,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    llm = HuggingFacePipeline(pipeline=pipe, model_kwargs={\"temperature\": 0})\n",
    "    return load_qa_chain(llm, \"stuff\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUERY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def fix_json(text):\n",
    "    json_str = copy.deepcopy(text)\n",
    "    if json_str.count(\"{\") != json_str.count(\"}\"):\n",
    "        while json_str.count(\"{\") % 2 != 0:\n",
    "            json_str = \"{\" + json_str\n",
    "            json_str = json_str.replace(\"}{\", \"},{\")\n",
    "        while json_str.count(\"}\") % 2 != 0:\n",
    "            json_str = json_str + \"}\"\n",
    "            json_str = json_str.replace(\"}{\", \"},{\")\n",
    "    if json_str.count(\"{\") < json_str.count(\"}\"):\n",
    "        while json_str.count(\"{\") != json_str.count(\"}\"):\n",
    "            json_str = \"{\" + json_str\n",
    "            json_str = json_str.replace(\"}{\", \"},{\")\n",
    "    elif json_str.count(\"{\") > json_str.count(\"}\"):\n",
    "        while json_str.count(\"{\") != json_str.count(\"}\"):\n",
    "            json_str = json_str + \"}\"\n",
    "            json_str = json_str.replace(\"}{\", \"},{\")\n",
    "    json_str = json_str.replace(\"\\n\", \"\")\n",
    "    if json_str.startswith(\"{{\") and json_str.endswith(\"}}\"):\n",
    "        json_str = json_str[1:-1]\n",
    "    json_str = json_str.replace('\"\"\"', '\"')\n",
    "    json_str = json_str.replace('\"\"', '\",\"')\n",
    "    return json_str\n",
    "\n",
    "\n",
    "def json_response(chain, docs, query, max_tries=6):\n",
    "    tries = 0\n",
    "    res = \"\"\n",
    "    while res == \"\" and tries < max_tries:\n",
    "        res = chain(dict(input_documents=docs, question=query))\n",
    "        res = res[\"output_text\"].strip()\n",
    "        res = res[res.find(\"{\") : res.rfind(\"}\") + 1]\n",
    "        tries += 1\n",
    "    tries = 0\n",
    "    while tries < max_tries:\n",
    "        try:\n",
    "            return dict(json_str=res, json=json.loads(fix_json(res)))\n",
    "        except:\n",
    "            tries += 1\n",
    "\n",
    "    return dict(json_str=res, json={})\n",
    "\n",
    "\n",
    "def info_json(chain, info_docs, max_tries=6):\n",
    "    info_query = \"\"\"Extract the order information like the numbers, dates, shipping address and total amount. Include the quote number too if found.\"\"\"\n",
    "    json_query = \"\\nReturn the text in JSON format. It must be compatible with json.loads.\"\n",
    "    suffix = \"\\nDon't tell me how to do it, just do it. Don't add any disclaimer.\"\n",
    "    info_query += json_query + suffix\n",
    "    return json_response(chain, info_docs, info_query, max_tries)\n",
    "\n",
    "\n",
    "def order_json(\n",
    "    chain,\n",
    "    order_docs,\n",
    "    max_tries=6,\n",
    "    get_parts=False,\n",
    "    chunk_size=4000,\n",
    "    chunk_overlap=0,\n",
    "):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\"], chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    json_query = \"\\nReturn the text in JSON format. It must be compatible with json.loads.\"\n",
    "    suffix = (\"\\nDon't tell me how to do it, just do it. Don't add any disclaimer.\",)\n",
    "    part_query = \"Include the part numbers if defined.\"\n",
    "    query = \"Extract the order items with full details and descriptions and prices.\"\n",
    "    if get_parts:\n",
    "        query += \" \" + part_query\n",
    "    query += suffix\n",
    "    query = query.strip()\n",
    "    items = chain(dict(input_documents=order_docs, question=query))[\"output_text\"].strip()\n",
    "\n",
    "    item_query = json_query\n",
    "    if get_parts:\n",
    "        item_query += \" \" + part_query\n",
    "    item_query += suffix\n",
    "    item_query = item_query.strip()\n",
    "\n",
    "    item_docs = splitter.create_documents([items])\n",
    "    return json_response(chain, item_docs, item_query, max_tries=max_tries)\n",
    "\n",
    "\n",
    "def pdf_to_info_order_json(path, chain, max_tries=6, get_parts=False):\n",
    "    info_order_dict = pdf_to_info_order_docs(path, get_parts=get_parts)\n",
    "    info_dict = info_json(\n",
    "        chain=chain, info_docs=info_order_dict[\"info_docs\"], max_tries=max_tries\n",
    "    )\n",
    "    order_dict = order_json(\n",
    "        chain=chain,\n",
    "        order_docs=info_order_dict[\"order_docs\"],\n",
    "        max_tries=max_tries,\n",
    "        get_parts=get_parts,\n",
    "    )\n",
    "    return {\"info\": info_dict, \"order\": order_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "llm_chain = qa_llm_chain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "data_path = Path(\"/home/hamza/demo_files/ap/\")\n",
    "data_path = Path(\"/home/hamza/demo_files/pdf\")\n",
    "file_name = \"wt13.pdf\"\n",
    "pdf = data_path / file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "info_order_json = pdf_to_info_order_json(pdf, llm_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_path = Path(\"/home/hamza/demo/json/\")\n",
    "# os.makedirs(json_path, exist_ok=True)\n",
    "# with open(Path(json_path / Path(pdf).stem).with_suffix(\".json\"), \"w\") as f:\n",
    "#     f.write(json.dumps({\"info\": info_json, \"items\": items_json}, indent=4))\n",
    "#     # f.write(json.dumps({\"info\": str(info_json), \"items\": items_res}, indent=4))\n",
    "#     # f.write(json.dumps({\"info\": str(info_res), \"items\": items_json}, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good = {\n",
    "#     \"wt4.pdf\": {\n",
    "#         \"info\": '{\"OrderNumber\": \"51020\", \"OrderDate\": \"7/11/2023\", \"ShipVia\": \"UPS GROUND V70010\", \"Terms\": \"NET 30\", \"VendorCode\": \"WILSON TOOL\", \"VendorPhone\": \"651-286-6125\", \"PurchasingAgent\": \"VANDERPOOL, BRYAN\", \"FOB\": \"ST PAUL, MN\", \"QuoteNumber\": \"21652926\", \"Quantity\": \"306.75\", \"OrderTotal\": \"$306.75\"}',\n",
    "#         \"items\": 'Sure, here are the order items with full details and descriptions and prices:\\n\\nOrder Item Description                   Quantity    Unit Price    Total\\n\\n12961 12961 B [1-1/4\"] Station Thick Slug Hugger, 2 Die Shape SD, 0.9590 IN, 0.0600 IN, RADIUS=0.0600 IN, $93.50 EA, $93.50\\n2964 12964  Station Thick Slug Hugger, 2 Die Shape SD, 1.3010 IN, 1.2220 IN, RADIUS=0.0600 IN, $213.25 EA, $213.25\\n\\nTotal: $306.75',\n",
    "#     },\n",
    "#     \"wt6.pdf\": {\n",
    "#         \"info\": \"{'PurchaseOrderID': 'PO94095', 'PurchaseOrderDate': '7/17/2023', 'ShippingAddress': {'Street': '1369 Cox Avenue', 'City': 'Erlanger', 'State': 'KY', 'PostalCode': '41018', 'Country': 'USA'}}\",\n",
    "#         \"items\": \"Order Items:\\n\\n1. American Precision, Punch Push\\n\\t* Part Number: 50074\\n\\t* Taxable: Yes\\n\\t* U.O.M.: 10.0000\\n\\t* Revision: 7/20/2023\\n\\t* Price: $8.5000\\n\\t* Extended Price: $85.0000\\n2. American Precision, Punch Push\\n\\t* Part Number: 6604\\n\\t* Taxable: Yes\\n\\t* U.O.M.: 1.0000\\n\\t* Revision: 7/20/2023\\n\\t* Price: $466.0000\\n\\t* Extended Price: $466.0000\\n\",\n",
    "#     },\n",
    "#     \"wt7.pdf\": {\n",
    "#         \"info\": \"{'Purchase Order Number': 'PO12722', 'Order Date': '7/11/2023', 'Buyer': 'dspooner', 'Vendor': 'WILSON TOOL INTERNATIONAL INC', 'Ship To': '4 Commerce Way Arden NC 28704', 'Vendor Phone': '(612) 426-1384 Ext. 0000', 'Order Total': '$137.50'}\",\n",
    "#         \"items\": \"Order Items:\\n\\n1. STATION THICK POSITIVE DIE\\nDescription: STATION THICK POSITIVE DIE\\nFOB: Each\\nUnit Price: $68.75\\nExtension Price: $68.75\\n\\n2. STATION THICK POSITIVE DIE\\nDescription: STATION THICK POSITIVE DIE\\nFOB: Each\\nUnit Price: $68.75\\nExtension Price: $68.75\",\n",
    "#     },\n",
    "#     \"wt13.pdf\": {\n",
    "#         \"info\": \"{'orderNumber': '21653677', 'customerNumber': '1016197', 'shipToAddress': {'street': '12912 Farnham Avenue', 'city': 'White Bear Lake', 'state': 'Minnesota', 'postalCode': '55110', 'country': 'U.S.A.'}}\",\n",
    "#         \"items\": \"Order Items:\\n\\n1. STATION THICK POSITIVE DIE\\nDescription: STATION THICK POSITIVE DIE\\nFOB: Each\\nUnit Price: $68.75\\nExtension Price: $68.75\\n\\n2. STATION THICK POSITIVE DIE\\nDescription: STATION THICK POSITIVE DIE\\nFOB: Each\\nUnit Price: $68.75\\nExtension Price: $68.75\",\n",
    "#     },\n",
    "#     \"wt25.pdf\": {\n",
    "#         \"info\": \"{'PurchaseOrderNumber': '155500', 'SupplierNumber': 'PONo', 'OrderDate': '6/29/2023', 'Tel': '262-343-8690', 'Fax': '262-343-8689', 'ShippingAddress': {'StreetAddress': '624 TowerDrive', 'City': 'Fredonia', 'State': 'WI', 'PostalCode': '53021', 'Country': 'USA'}}\",\n",
    "#         \"items\": \"| Order Item | Part No | Description | Quantity | Price |\\n| --- | --- | --- | --- | --- |\\n| 1 | P5367-IMPAXVARIABLE | P5367-IMPAXVARIABLEINCH | 2 | 0.00 |\\n| 2 | P5367-IMPAXVARIABLE | P5367-IMPAXVARIABLEINCH | 4 | 0.00 |\\n| 3 | P5367-IMPAXVARIABLE | P5367-IMPAXVARIABLEINCH | 6 | 0.00 |\\n| Grand Total | 0.00 |\\n\\nNote: The answer is in a table format, with the order items listed in the first column, their part numbers listed in the second column, the descriptions listed in the third column, the quantities listed in the fourth column, and the prices listed in the fifth column. The grand total is listed at the bottom of the table.\",\n",
    "#     },\n",
    "#     \"wt26.pdf\": {\n",
    "#         \"info\": \"{'orderNumber': '0000193617', 'purchaseDate': '6/29/2023', 'shipToAddress': {'street': '4328 S York Hwy', 'city': 'Saint Paul', 'state': 'MN', 'postalCode': '55170-7676', 'country': 'USA'}}\",\n",
    "#         \"items\": \"Order Items:\\n\\n1. MISC (50075)\\n* Description:\\n* Ordered: 20.000\\n* Received Back: 0.000\\n* UOM: Each\\n* Unit Cost: 8.750\\n* Amount: 175.00\\n2. MISC (8141)\\n* Description:\\n* Ordered: 20.000\\n* Received Back: 0.000\\n* UOM: Each\\n* Unit Cost: 4.750\\n* Amount: 95.00\\n3. MISC (51083)\\n* Description:\\n* Ordered: 20.000\\n* Received Back: 0.000\\n* UOM: Each\\n* Unit Cost: 16.500\\n* Amount: 330.00\\n4. MISC (50079)\\n* Description:\\n* Ordered: 20.000\\n* Received Back: 1.000\\n* UOM: Each\\n* Unit Cost: 1.000\\n* Amount: 20.00\\n\\nFreight: 0.00\\n\\nTotal: 620.00\",\n",
    "#     },\n",
    "#     \"wt27.pdf\": {\n",
    "#         \"info\": \"{'Purchase Order ID': '140916', 'Purchase Order Date': '7/13/23', 'Ship To Address': {'Street Address': '3855 64th Avenue SE', 'City': 'Calgary', 'Province': 'AB', 'Postal Code': 'T2C 2V5', 'Country': 'Canada'}}\",\n",
    "#         \"items\": \"Order Items:\\n\\n1. Trumpf Size 1 Flat Punch Shape 2.36mm\\nDescription: Flat punch shape\\nQuantity: 2\\nUnit Price: $108.50\\n\\n2. Trumpf Size 1 Cupped GL Die Shape RT\\nDescription: Cupped GL die shape RT\\nQuantity: 2\\nUnit Price: $110.75\\n\\nTotal PO Value: $438.50\",\n",
    "#     },\n",
    "#     \"wt41.pdf\": {\n",
    "#         \"info\": \"{'PO Number': '58900', 'Vendor Name': 'KATHY LIMANEN', 'Ship To Address': {'Street': '5657 Prospect Street', 'City': 'High Point', 'State': 'NC', 'Postal Code': '27263', 'Country': 'USA'}}\",\n",
    "#         \"items\": \"Order Items:\\n\\nLine Part Number/Rev/Description     Order Qty         Unit Price   Ext Price\\n\\n1  25771                             2.00 EA         100.50000 /1  201.00\\n\\n* Trumpf 241 Flat Punch Shape 2.36mm-30.00mm RT 0.5000 IN X 0.1250 INFLAT,ULTIMA PREMIUM PUNCH STEEL\\n\\n\\nOrder Quantity: 2.00 EA\\nUnit Price: 100.50000 / 1\\nExtension Price: 201.00\\n\\n\\n\\n2  26740                             2.00 EA         110.75000 /1  221.50\\n\\n* Trumpf Size 1 Cupped GL Die Shape RT 0.5000 IN X 0.1250 IN 0.0120 IN, CLEARANCESHAPE 1=0.0000 DEG\\n\\n\\nOrder Quantity: 2.00 EA\\nUnit Price: 110.75000 / 1\\nExtension Price: 221.50\\n\\n\\nNote:\\nThe order items with full details and descriptions and prices are:\\n* Trumpf 241 Flat Punch Shape 2.36mm-30.00mm RT 0.5000 IN X 0.1250 INFLAT,ULTIMA PREMIUM PUNCH STEEL (Order Quantity: 2.00 EA, Unit Price: 100.50000 / 1, Extension Price: 201.00)\\n* Trumpf Size 1 Cupped GL Die Shape RT 0.5000 IN X 0.1250 IN 0.0120 IN, CLEARANCESHAPE 1=0.0000 DEG (Order Quantity: 2.00 EA, Unit Price: 110.75000 / 1, Extension Price: 221.50)\\n\\nPlease let me know if you need further assistance.\",\n",
    "#     },\n",
    "#     \"wt45.pdf\": {\n",
    "#         \"info\": \"{'Order Number': '17512', 'Order Date': '7/13/2023', 'Vendor Phone': '800-328-9646', 'Purchasing Agent': 'Joe Astarita', 'Vendor FAX': '123456789', 'FOB': ',', 'Quantity Part Number': '123456', 'Date': '7/13/2023', 'Unit': '183.17', 'Ship Via': 'United Parcel Service'}\",\n",
    "#         \"items\": \"Order Items:\\n\\n* P/N 2385 A - TOOLING - CUSTOM - $39.5200 EA - $39.52\\n* P/N 13045 A - TOOLING - CUSTOM - $10.4100 EA - $10.41\\n* P/N 2907 A - TOOLING - CUSTOM - $133.2400 EA - $133.24\\nTotal Order Amount: $183.17\",\n",
    "#     },\n",
    "#     # \"wt49.pdf\": {\n",
    "#     #     \"info\": \"{'PO': 17938, 'DATE': '24/06/2023', 'BILL TO': 'TROQUELADOS Y LAMINADOS MONTERREY', 'RFC': 'TLM85122335A', 'PROVIDER': 'PI0133 Mariano Escobedo, 3587', 'SHIP TO': {'STREET_ADDRESS': 'BLVD. DIAZ ORDAZ', 'CITY': 'SANTA MARIA', 'POSTAL_CODE': '64500', 'COUNTRY': 'MX'}}\",\n",
    "#     #     \"items\": 'Order Items:\\n1. GF6048204900 - 1882 E [4-1/2\"] STATION THICK STRIPPER\\nDescription: 1882 E [4-1/2\"] STATION THICK STRIPPER\\nQuantity: 1\\nPrice: $118.80\\n\\n2. GF6048204900 - SHIPPING & IMPORT\\n\\nDescription: SHIPPING & IMPORT\\n\\nQuantity: 1\\n\\nPrice: $120.00\\n\\n\\nTotal: $248.80\\n\\n\\nPlease provide me with the exact details of each order item along with its description, quantity, and price.',\n",
    "#     # },\n",
    "#     \"wt61.pdf\": {\n",
    "#         \"info\": \"{'order': {'purchase_order_number': '863959', 'purchase_date': '6/29/2023', 'shipping_address': {'street_address': '845 Corporate Way', 'city': 'Sumter', 'state': 'US', 'postal_code': '29154', 'country': 'US'}}}\",\n",
    "#         \"items\": \"Order Items:\\n\\n1. MAINT_SUPPLIES\\nDescription: Trumpf Size 1 To Size 2 Trumpf Die Adapter For\\nQuantity: 12\\nUnit Cost: 244.93\\nTotal Cost: 2,939.16\\n\\nPlease let me know if you want me to do anything else.\",\n",
    "#     },\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
